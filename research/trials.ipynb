{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6ae7bfc",
   "metadata": {},
   "source": [
    "# performing \"research\" for the chatbot \n",
    "##### (RAG + safe Pandas function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5d2459",
   "metadata": {},
   "source": [
    "### Check to see if <b>jupyter notebook is running</b> and import the libaries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "634db173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "665f98f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\chatbot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import necessary libaries\n",
    "import os\n",
    "import pandas as pd\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from typing import List\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39335c26",
   "metadata": {},
   "source": [
    "### move the working directory up to access data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ccc2c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\User\\\\Downloads\\\\Personal Projects\\\\Generative AI Chatbot\\\\Building-a-Generative-AI-Chatbot-with-RAG\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking working directory, moved it up by one so that the data folder is accessiable\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f969228e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\User\\\\Downloads\\\\Personal Projects\\\\Generative AI Chatbot\\\\Building-a-Generative-AI-Chatbot-with-RAG'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# moves working directory up\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcaba5",
   "metadata": {},
   "source": [
    "### data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6c84b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Visit ID', 'Patient ID', 'Hospital ID', 'Hospital Name', 'Region',\n",
       "       'Visit Date', 'Day of Week', 'Season', 'Time of Day', 'Urgency Level',\n",
       "       'Nurse-to-Patient Ratio', 'Specialist Availability',\n",
       "       'Facility Size (Beds)', 'Time to Registration (min)',\n",
       "       'Time to Triage (min)', 'Time to Medical Professional (min)',\n",
       "       'Total Wait Time (min)', 'Patient Outcome', 'Patient Satisfaction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data \n",
    "df = pd.read_csv('data/ER Wait Time Dataset.csv')\n",
    "df[\"Visit Date\"] = pd.to_datetime(df[\"Visit Date\"])\n",
    "\n",
    "# check column names so that data can be rewritten and stored as document\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d4719f",
   "metadata": {},
   "source": [
    "### load <b> all data </b>from data folder (assuming consistent format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58715070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function loads multiple files from file_path and returns it as a whole \n",
    "def load_csv_files(file_path):\n",
    "    documents = []\n",
    "\n",
    "    for file in os.listdir(file_path):\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_path = os.path.join(file_path, file)\n",
    "\n",
    "            df = pd.read_csv(file_path)\n",
    "            df[\"Visit Date\"] = pd.to_datetime(df[\"Visit Date\"], errors=\"coerce\")\n",
    "\n",
    "            # the conversion of data here is hard coded, assuming datasets in the folder have the same columns/format\n",
    "            for _, row in df.iterrows():\n",
    "                content = f\"\"\"\n",
    "                On {row['Visit Date']} at {row['Hospital Name']} (Region: {row['Region']}),\n",
    "                urgency level was {row['Urgency Level']}.\n",
    "                Total wait time was {row['Total Wait Time (min)']} minutes.\n",
    "                Patient outcome was {row['Patient Outcome']}.\n",
    "                Patient satisfaction was {row['Patient Satisfaction']}.\n",
    "                \"\"\"\n",
    "\n",
    "                documents.append(\n",
    "                    Document(\n",
    "                        page_content=content.strip(),\n",
    "                        metadata={\n",
    "                            \"source_file\": file,\n",
    "                            \"hospital\": row[\"Hospital Name\"],\n",
    "                            \"region\": row[\"Region\"]\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fcda3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check length of data\n",
    "extracted_data = load_csv_files(\"data\")\n",
    "len(extracted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5d8776",
   "metadata": {},
   "source": [
    "### <b>vector storing process</b> (in Pinecone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "326bd435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify the data and standarize for vector storing\n",
    "\n",
    "def filter_to_minimal_docs(docs: List[Document]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Given a list of document objects, return a new list of document objects\n",
    "    containing only 'source' in metadata and the original page_content.\n",
    "    \"\"\"\n",
    "    minimal_docs: List[Document] = []\n",
    "    for doc in docs:\n",
    "        src = doc.metadata.get(\"source_file\")\n",
    "\n",
    "        minimal_docs.append(\n",
    "            Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata={\"source\": src}\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return minimal_docs\n",
    "\n",
    "minimal_docs = filter_to_minimal_docs(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "591f6b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chunks: 5000\n"
     ]
    }
   ],
   "source": [
    "# split the documents into smaller chunks\n",
    "def text_split(minimal_docs):\n",
    "    text_spliter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20\n",
    "    )\n",
    "    text_chunks = text_spliter.split_documents(minimal_docs)\n",
    "    return text_chunks\n",
    "\n",
    "text_chunks = text_split(minimal_docs)\n",
    "print(f\"Number of Chunks: {len(text_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e7e5994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7748\\1077763997.py:6: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceBgeEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "def download_embeddings():\n",
    "    \"\"\"\n",
    "    Download and return the HuggingFace Embeddings model.\n",
    "    \"\"\"\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceBgeEmbeddings(\n",
    "        model_name=model_name\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "embedding = download_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4683822e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceBgeEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, query_instruction='Represent this question for searching relevant passages: ', embed_instruction='', show_progress=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dea6242c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the needed API keys\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5da39d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53363fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign pinecone api key to variable pc\n",
    "pinecone_api_key = PINECONE_API_KEY\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20f8931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating index into pinecone if not already present\n",
    "index_name = \"genai-chatbot\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name = index_name,\n",
    "        dimension = 384, # dimension of embeddings\n",
    "        metric = \"cosine\", # cosine similarity\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d74ce",
   "metadata": {},
   "source": [
    "if embeddings are already stored, <b>do not need to run the markdown code below</b>. <br>\n",
    "If not duplicated embeddings will be created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4912bff5",
   "metadata": {},
   "source": [
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents = text_chunks,\n",
    "    embedding = embedding,\n",
    "    index_name = index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b081172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load existing index\n",
    "\n",
    "# embed each chunk and upsert the embeddings into your pinecone index\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eec423a",
   "metadata": {},
   "source": [
    "adding more data into existing Pinecone Index, if needed code is:\n",
    "\n",
    "dswith = Document(\n",
    "    page_content=\"insert new content\"\n",
    "    metdadata={\"source\": \"source\"}\n",
    ")\n",
    "\n",
    "docsearch.add_documents(documents=[dwsith])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8a631d",
   "metadata": {},
   "source": [
    "### Retriving Text Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a507bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrive the 3 most relevant chunks\n",
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac1eda2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='8ee5d76d-5740-44af-91a8-e9ae97153687', metadata={'source': 'ER Wait Time Dataset.csv'}, page_content='On 2024-03-19 23:48:51 at Summit Health Center (Region: Urban),\\n                urgency level was Low.\\n                Total wait time was 100 minutes.\\n                Patient outcome was Admitted.\\n                Patient satisfaction was 1.'),\n",
       " Document(id='0e48a08f-bc3a-49dd-873c-6f8a999e31b9', metadata={'source': 'ER Wait Time Dataset.csv'}, page_content='On 2024-09-17 09:42:50 at Summit Health Center (Region: Urban),\\n                urgency level was Low.\\n                Total wait time was 120 minutes.\\n                Patient outcome was Admitted.\\n                Patient satisfaction was 1.'),\n",
       " Document(id='c641fc04-97a6-4726-ab4e-a8d683600415', metadata={'source': 'ER Wait Time Dataset.csv'}, page_content='On 2024-09-08 15:41:23 at Summit Health Center (Region: Urban),\\n                urgency level was Low.\\n                Total wait time was 120 minutes.\\n                Patient outcome was Admitted.\\n                Patient satisfaction was 1.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing to see docs retrived\n",
    "retrieved_docs = retriever.invoke(\"what is the satisfaction score of a patient visting Summit Health Center in the Evening on 1/1/12024\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7235d32",
   "metadata": {},
   "source": [
    "### creating safe Pandas functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3e95f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric directionary for semantic meaning\n",
    "METRIC_MAP = {\n",
    "    \"satisfaction\": \"Patient Satisfaction\",\n",
    "    \"wait_time\": \"Total Wait Time (min)\",\n",
    "    \"registration_time\": \"Time to Registration (min)\",\n",
    "    \"triage_time\": \"Time to Triage (min)\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bca0850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM to extract metric type\n",
    "def detect_metric(question):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    The user asked: \"{question}\"\n",
    "\n",
    "    Identify:\n",
    "    1) What metric they want (e.g. satisfaction, wait time, triage time)\n",
    "    2) What operation they want (average, count)\n",
    "\n",
    "    Return response in this format:\n",
    "    metric=<metric_name>; operation=<average_or_count>\n",
    "    \"\"\"\n",
    "\n",
    "    response = chatModel.invoke(prompt)\n",
    "    text = response.content.strip()\n",
    "\n",
    "    parts = {}\n",
    "    for part in text.split(\";\"):\n",
    "        if \"=\" in part:\n",
    "            key, value = part.split(\"=\")\n",
    "            parts[key.strip()] = value.strip().lower()\n",
    "\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03e38c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dynamic_metric(df, metric_name, operation, **filters):\n",
    "\n",
    "    filtered = df.copy()\n",
    "\n",
    "    # Filter by hospital\n",
    "    if filters.get(\"hospital\"):\n",
    "        filtered = filtered[filtered[\"Hospital Name\"] == filters[\"hospital\"]]\n",
    "\n",
    "    # Filter by date safely\n",
    "    if any(filters.get(k) for k in [\"day\", \"month\", \"year\"]):\n",
    "        # ensure date column is datetime\n",
    "        if not pd.api.types.is_datetime64_any_dtype(filtered[\"Visit Date\"]):\n",
    "            filtered[\"Visit Date\"] = pd.to_datetime(filtered[\"Visit Date\"], errors=\"coerce\")\n",
    "        mask = pd.Series(True, index=filtered.index)\n",
    "        if filters.get(\"day\"):\n",
    "            mask &= filtered[\"Visit Date\"].dt.day == filters[\"day\"]\n",
    "        if filters.get(\"month\"):\n",
    "            mask &= filtered[\"Visit Date\"].dt.month == filters[\"month\"]\n",
    "        if filters.get(\"year\"):\n",
    "            mask &= filtered[\"Visit Date\"].dt.year == filters[\"year\"]\n",
    "        filtered = filtered[mask]\n",
    "\n",
    "    if len(filtered) == 0:\n",
    "        return None\n",
    "\n",
    "    # Metric routing\n",
    "    column = None\n",
    "    if \"satisfaction\" in metric_name.lower():\n",
    "        column = \"Patient Satisfaction\"\n",
    "    elif \"wait\" in metric_name.lower():\n",
    "        column = \"Total Wait Time (min)\"\n",
    "    elif \"triage\" in metric_name.lower():\n",
    "        column = \"Time to Triage (min)\"\n",
    "\n",
    "    if operation == \"count\":\n",
    "        # COUNT respects filters automatically\n",
    "        return len(filtered)\n",
    "\n",
    "    if column is None:\n",
    "        return None\n",
    "\n",
    "    return round(filtered[column].mean(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b1ddeb",
   "metadata": {},
   "source": [
    "### initilaizing <b>chat model and prompts</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "041b22f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatModel = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e491b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initilize system prompt\n",
    "system_prompt = (\n",
    "    \"You are an analytics assistant for question-answering tasks.\"\n",
    "    \"Use the following pieces of retrieved context to answer\"\n",
    "    \"the question. If you don't know the answer, say that you\"\n",
    "    \"don't know. User three sentences maximum and keep the\"\n",
    "    \"answer concise\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\")\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6cfa9e",
   "metadata": {},
   "source": [
    "### parameters extraction for analytical questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8a20953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "\n",
    "def extract_parameters(question):\n",
    "    \"\"\"\n",
    "    Extract hospital, day, month, year from question.\n",
    "    Works even if month is a name like 'April'.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    params = {\"hospital\": None, \"day\": None, \"month\": None, \"year\": None}\n",
    "\n",
    "    # extract date from question\n",
    "    date_match = re.search(r'(\\w+\\s\\d{1,2},\\s?\\d{4})', question)\n",
    "    if date_match:\n",
    "        date_str = date_match.group(1)\n",
    "        try:\n",
    "            dt = parser.parse(date_str)\n",
    "            params[\"day\"] = dt.day\n",
    "            params[\"month\"] = dt.month\n",
    "            params[\"year\"] = dt.year\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # optionally extract hospital names if you have a list\n",
    "    hospitals = df[\"Hospital Name\"].unique()\n",
    "    for h in hospitals:\n",
    "        if h.lower() in question.lower():\n",
    "            params[\"hospital\"] = h\n",
    "            break\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faf9f60",
   "metadata": {},
   "source": [
    "### whole RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e99d5b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all relevant documents into single return prompt for LLM\n",
    "question_answer_chain = create_stuff_documents_chain(chatModel, prompt)\n",
    "# full RAG pipeline (Retrival + Generation)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9931516b",
   "metadata": {},
   "source": [
    "### main chatbot code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ee576f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(question):\n",
    "\n",
    "    # extract filters safely\n",
    "    params = extract_parameters(question)\n",
    "\n",
    "    # detect metric & operation\n",
    "    # simple keyword-based metric detection\n",
    "    if \"satisfaction\" in question.lower():\n",
    "        metric_name = \"satisfaction\"\n",
    "        operation = \"average\"\n",
    "    elif \"wait\" in question.lower():\n",
    "        metric_name = \"wait\"\n",
    "        operation = \"average\"\n",
    "    elif \"visit count\" in question.lower() or \"number of visits\" in question.lower():\n",
    "        metric_name = \"visit\"\n",
    "        operation = \"count\"\n",
    "    else:\n",
    "        # fallback to descriptive â†’ RAG\n",
    "        response = rag_chain.invoke({\"input\": question})\n",
    "        return response[\"answer\"]\n",
    "\n",
    "    result = compute_dynamic_metric(df, metric_name, operation, **params)\n",
    "\n",
    "    if result is None:\n",
    "        return \"No data found for that query.\"\n",
    "\n",
    "    # format final answer\n",
    "    return f\"The {metric_name} for your query is {result}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1117e54f",
   "metadata": {},
   "source": [
    "#### Testing of Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d07c922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The satisfaction for your query is 2.78.\n"
     ]
    }
   ],
   "source": [
    "# question 1\n",
    "question = \"What is the average customer satisfaction score for Summit Health Center in Jan 2024?\"\n",
    "answer = chatbot(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45e31b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The visit for your query is 23.\n"
     ]
    }
   ],
   "source": [
    "# question 2\n",
    "question = \"What is the patient visit count on April 4, 2024\"\n",
    "answer = chatbot(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f402140f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riverside Medical Center is in an urban region.\n"
     ]
    }
   ],
   "source": [
    "# question 3\n",
    "question = \"What region is Riverside Hospital in?\"\n",
    "answer = chatbot(question)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
